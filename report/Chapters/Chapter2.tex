
\chapter{Automating PPR discovery} 
\label{chap:methods}

\lettrine{M}{ost} 
sequenced genomes are also annotated with information about the genes they
encode a specific locations.
These annotations are usually helpful when navigating the genome as many
are the result of empirical study.
The majority of PPRs have not been studied in detail, however, and thus their
annotation is unreliable and doesn't contain information about 
the PPR motifs found within the proteins.

For this reason it was necessary to develop routines for discovering and
extracting PPR proteins from unannotated genomes, using a hidden Markov model
of the characteristic repeat motifs to find likely targets.
Having identified PPRs, we would like to be able to predict their binding
locations within organelles.

The development of algorithms to achieve these things is discussed in this
chapter.

\section{pyHMMER}
\label{ssec:pyHMMER}

The HMMER suite provides all of the basic algorithms required in order to
perform an HMM search on a target amino acid sequence, but it does have some
limitations.

The first is that it is a command line program and does not have bindings to
any programming language.
HMMER reads inputs from files, and writes out tabular output data to file which
would be very time consuming to parse by hand.

HMMER cannot translate sequences on the fly -- is can only compare a protein 
model with a protein target, and so the genome must be translated before 
HMMER is invoked.
There are a total of six possible reading frames (3 forwards and 3 backwards, 
due to the 3:1 nature of translation) and the genome must be searched in each
of these six frames.

HMMER is not commercial software and is developed by a group of scientists at
the Howard Hughes Medical Institute (HHMI) under an open licence for research
purposes.
As such, it contains a number of minor bugs which are not fatal to the
software's functionality, but can sometimes cause problems
under particular circumstances.
The most problematic of these causes enormous
memory usage (over 20GB\footnote{One particular instance of this error is due
to an unsigned integer wrap-around which causes significantly more memory to be
requested from the operating system than could possibly be needed}) and
prevents the program from completing.

In order to overcome these issues, a python wrapper for HMMER called
pyHMMER was designed and written as part of this project.
Python was chosen as the main language mainly because of its
excellent library support -- for example the biopython library solved many of 
the difficulties when working with biological sequences without extra effort.

pyHMMER does not implement all the features available in HMMER, but rather it
implements those which were most vital to this project.
Its main features are -
\begin{itemize}
  \item Read and write \emph{.hmm} files, HMMER's custom file format for
    storing HMMs
  \item Execute searches using 
    \emph{hmmsearch} and \emph{jackhmmer}, accepting all valid command line
    arguments and returning their output as biopython objects, 
    handling the creation and removal of all the necessary 
    temporary files automatically
  \item Seamlessly perform six-frame translations on the fly (implemented in C
    for best performance) and correctly map the location of each match to the 
    original target alphabet
  \item Automatically terminate HMMER processes which attempt to allocate more
    memory than the system can sensibly be expected to 
    provide\footnote{Linux only} and then call
    HMMER sequentially with subsections of the target, automatically mapping
    all matches back to the original target
  \item Fully unit-tested with python's \emph{unittest} framework
\end{itemize}
pyHMMER has been developed under an open-source licence and is freely available
from \emph{https://github.com/haydnKing/pyHMMER}, although all code used in
this project was written by myself.


\section{Automated PPR Detection and Extraction}
\label{sec:ppr_extraction}

Several algorithms were developed and compared in order to extract PPRs from
unannotated genomes.
The results of each algorithm were compared with experimentally validated PPRs
and the best chosen.

Before development could begin, a HMM of the PPR repeat motif was required.
There are four such models available in
Pfam\footnote{http://pfam.sanger.ac.uk/search/keyword?query=PPR}, and each one
was tested on known PPRs in order to discover which model worked best when
searching for motifs.
It was found the PPR\_3 model is most sensitive to the motifs, yet still
returns few false positives.

Armed with this model, the final algorithm for discovering PPRs proceeds as
follows for each chromosome within the genome
\begin{enumerate}
  \item \label{alg:first_pass}
    Perform a HMM search on the whole sequence. This will discover the most
    obvious motifs only
  \item \label{alg:grouping}
    Cluster the motifs into groups such that members of the same group are on
    the same strand and are within a certain distance of each other
  \item \label{alg:envelopes} 
    For each group, extract and `envelope' region containing each motif in the
    group along with large margins either side. 
  \item \label{alg:second_pass}
    Search each envelope region for PPR motifs. This search is more
    focussed than the previous one and will reveal more motifs than previously.
    Discard any envelopes which contain only one motif.
  \item Starting from the first position of the first motif, search backwards
    one codon at a time until a start codon (`ATG') is reached
  \item Starting from the last position in the final motif, search forwards one
    codon at a time until a stop codon is reached (`TGA', `TAG' or `TAA').
    Extract the putative PPR from between the start and stop codon
  \item \label{alg:overlap}
    Check for PPRs which overlap. 
    Each set of overlapping proteins should be removed and a new, larger
    envelope extracted. The algorithm then continues again from step
    \ref{alg:second_pass} with the new envelopes
  \item \label{alg:large_proteins}
    Check for PPRs where the motifs have filled the envelopes -- i.e. ones
    which are missing a start or a stop codon due to not having searched far
    enough. Extract larger envelopes for these proteins and continue from step
    \ref{alg:second_pass}
  \item \label{alg:reluctance}
    Search each protein for gaps between motifs which are the correct size
    to fit a PPR motif. Search these regions specifically, increasing HMMER's
    sensitivity to look for reluctant PPR
    motifs. Also search the beginning and the end of the protein in this way
  \item \label{alg:remove_gaps}
    Search each protein for small (2/3 codon) gaps between the motifs and
    move the end position of the previous motif in order to fill these gaps.
    This allows the motifs to be classified as P, L or S
  \item \label{alg:classification} 
    Classify the proteins depending on which types of motifs they contain.
    Extract the protein sequence of each tail sequence and classify it using
    \emph{jackhmmer} to search for the known consensus sequences for E, E+ and
    DYW motifs
  \item \label{alg:subcellular_location}
    Predict each protein's sub-cellular location using the \emph{targetP}
    program
\end{enumerate}
A brief discussion of the rationale and implementation of the most important 
steps follows.

The reason why the motifs found in step \ref{alg:first_pass} cannot simply be
accepted is due to the degenerate nature of the motifs.
It would be possible to decrease HMMER's reporting threshold as to return all
possible motifs but since the search space is large and the model accepts a
wide range of sequences, there would be a large number of false positives.
By using default values for these thresholds there is unlikely to be a problem 
as HMMER is designed to show the most probable matches and only a few of
the possible false positives.
The presence of a few false positives at this stage is not an issue because the
chance of finding several false positives immediately adjacent to each other 
(as would be required to pass the later stages of the algorithm) is highly 
unlikely.

Having found the most obvious motifs, step \ref{alg:grouping} groups motifs
which are believed to belong to the same protein.
Initially this was restricted to motifs which were in the same reading frame
(i.e. the gaps between start of each motif were multiples of three), 
but this was later expanded to all motifs on the same strand, as introns 
(see sections \ref{sec:transcription} and \ref{sec:translation}) 
are known to be present in some PPR motifs.
Experiment showed that grouping motifs which were within $1500bp$ of each other
gave good results.
Grouping was implemented by first sorting the motifs into ascending order and 
then searching through linearly giving a cost of $O(n \log n)$ rather than the 
cost of $O(n^2)$ required for exhaustively comparing each motif.

Envelopes are then extracted from these groups in step \ref{alg:envelopes}.
The term `envelope' is borrowed from HMMER's output and refers to the fact that
we expect there to be a PPR somewhere within this region, but we are not sure
where exactly.
For envelopes on the reverse strand, the sequence is extracted such that it
reads in the 5' to 3' direction on that strand.
It is important to maintain a record of where in the target sequence the
envelope came from, as this information may be required later in the algorithm.
A margin of $1000bp$ either side of the group was found to give good results.

The search space in step \ref{alg:second_pass} is several orders of magnitude 
smaller than the first pass and so the chances of finding multiple high-scoring 
matches by chance are negligible.
Shortening the target in this way effectively moves HMMER's baseline for
scoring matches such that lower scoring matches which would previously have 
been written off as noise are now treated as legitimate matches.

Steps \ref{alg:overlap} and \ref{alg:large_proteins} effectively correct for
situations where the parameter values chosen for grouping and envelope
extraction do not perform well.
For example, if step \ref{alg:first_pass} detects the first and last motifs
from a particularly long PPR then these will be treated as belonging to 
separate proteins up until this point.
Similarly, if only one motif was detected then the size of the actual protein
may be larger than the envelope which is extracted.

These two steps introduce loops into the algorithm and thus introduce the
worrying possibility of an infinite loop preventing the algorithm from
completing.
In the case of step \ref{alg:overlap} this cannot happen as for each
iteration of the loop the number of putative proteins is half that of the
previous loop, meaning that no infinite loop is possible.
An infinite loop is also impossible in \ref{alg:large_proteins}, as the growth
of the envelope is limited by the size of the search query. 
However, since each loop iteration is expensive and adds only a constant 
length to the envelope this could take quite some time in the worst case.
To protect from this, a large upper bound was placed on the maximum length of 
a protein.

Proteins which are input to step \ref{alg:reluctance} often contain gaps of
around 35 amino acids -- the correct size for a repeat motif -- and comparison
with known proteins shows that a motif should indeed be placed in this region.
These motifs can be found by searching these regions with a lower reporting
threshold than the default.
A plausible explanation of these poorly conserved motifs is that the presence of
relatively well conserved (and thus well folded) regions on either side of the
degenerate motif increases its tendency to fold correctly.
However it could also be the case that these regions simply represent a gap in
the recognition chain (where any base would be accepted) or an intron; more
empirical results are needed in order to determine this in every case.
Setting each of the parameters \emph{F1}, \emph{F2} and \emph{F3} to $0.5$ 
gave a reasonable trade-off between finding likely reclusive motifs and 
rejecting random sequences.

Studies such as \citet{Lurin2004} have shown that tandem PPR repeat motifs tend
not to have small gaps between them.
Since pyHMMER returns the location of the HMMER model, each match is the same
length as the model.
This is corrected for in step \ref{alg:remove_gaps}, such that the motifs can
be classified as type P (length~$=$~35aa), L (length~$>$~35aa) or 
S (length~$<$~35aa).

The final two stages classify the extracted proteins depending on their type
and sub-cellular targeting.
Step \ref{alg:classification} makes use of the \emph{jackhmmer} program which
iteratively constructs HMM models of a consensus sequence based on a target
sequence and is supported by pyHMMER.
The final step uses \emph{targetP}, a well respected prediction algorithm for
sub-cellular localisation\citep{targetP}.

\section{Predicting PPR Binding regions}
\label{sec:ppr_binding_prediction}

Given an identified and well annotated PPR protein, predicting the RNA 
footprint to which is binds is not straightforward.
In the case of TALEs (section \ref{sec:intro_binding}), a well known mapping
exists between the amino acids at specific locations within the repeat and the
preferred DNA base of that repeat.
Unfortunately, such a mapping has yet to be confirmed for the PPR family,
although two main suggestions have been made, by \citet{Barkan2012} and by
\citet{Yagi2013}.

Since neither the structure of of the PPR motif or of a PPR-RNA complex
has been solved, the only method to elucidate the rules governing binding
preferences is by looking for statistical dependencies between the amino-acid
sequence and RNA footprint of known PPR-RNA pairs.
This is the strategy used by both papers mentioned above and so they lead to
similar results.
The papers each provide methodologies to convert each PPR motif into a
distribution over each the symbols in RNA, $\{A,C,G,U\}$.

The next two sections outline methods for discovering likely binding sites
in a particular target given a sequence of such distributions.

\subsection{Profile Hidden Markov Models}
\label{sec:hmm_binding}

The first method which was tested was using pHMMs, as this would allow the use
of HMMER's advanced searching algorithms.
This seems a simple task -- the probabilities given at each motif give the
emission probabilities at each node, insert probabilities can be uniform and
the transition probabilities can be determined empirically.

The first issue which arises is that pHMM models which are used for searching
with HMMER must be normalised in order to make score calculations.
This involves estimating the parameters of the distribution of model scores 
for random sequences.
A program called \emph{hmmsim} exists in the HMMER package for just 
this purpose, however the program is not a mainstream part of the HMMER package
and is present more as a tool for testing HMMER's internals rather than use by
the end user.
As a result, it is not as stable as other HMMER tools and has not been tested
with all possible use cases.
Unfortunately, one particular unanticipated use case is the normalisation of a
DNA model -- \emph{hmmsim} is hard-coded to accept only protein models as this
is HMMER's primary use case.

This problem was circumvented by writing the model as a protein model by
expanding the probabilities of each of the four bases to those of the 20 
amino acids (i.e. the first 5 amino acids corresponding to an `A' etc\ldots).
However models which had been normalised in this way did not prove to be
effective when searching large sequences even when a known high scoring
sequence was inserted into an otherwise random target.

For this reason, pHMMs were abandoned as a method of predicting binding
footprints.


\subsection{Position-Specific Scoring Matrices (PSSMs)}
\label{sec:pssm_binding}

PSSMs are another common technique for discovering particular sequences in a
target.
They are similar in nature to pHMMs (which can be considered as a
generalisation of the PSSM), but are generally significantly simpler.
Each column of the matrix corresponds to a particular position in the sequence and
the rows specify the probability of each possible symbol appearing in that
location.

The probabilities are generally stored as logarithms, such that the probability
of any particular sequence of length $N$ is simply the summation of $N$ values
from the sequence.
PSSMs can incorporate the background distribution by storing log-odds scores
such that
\begin{equation*}
  m_{i,j} = \log {\frac{p_{i,j}}{b_i}}
\end{equation*}
where $p_{i,j}$ is the probability of observing symbol $i$ at location $j$ and
$b_i$ is the probability of observing symbol $i$ in the background sequence.

PSSMs are easy to construct given the distribution of symbols at each location,
but require more work when searching for highly scoring sequences, particularly
given that PPR binding footprints often contain bases which are not actually
bound to a motif -- an insert in pHMM terminology.

A simple algorithm for finding maxima proceeds as:
\begin{enumerate}
  \item \label{alg:score} 
    Score the sequence at possible model position in the sequence
  \item \label{alg:nms}
    Discard the positions which aren't a local maximum
  \item \label{alg:gaps}
    For each maximum, try inserting gaps at each location in the model to
    attempt to increase the score of the maximum, then return the highest
    scoring matches
\end{enumerate}
This algorithm is somewhat inefficient, but it returns the highest scoring
alignments in a reasonable time.
Step \ref{alg:score} may seem the most inefficient as every possible alignment
is tested, but this actually interacts rather well with the memory cache on
modern computers as it searches through the data linearly.
Step \ref{alg:gaps} is in fact the rate limiting step in most cases, as the
number of possible combinations of gap locations grows rapidly with both the
length of the model and the number of gaps.

